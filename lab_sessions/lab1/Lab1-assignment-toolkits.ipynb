{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kathryn/git/ba-text-mining/lab_sessions/lab1/Lab1-apple-samsung-example.txt\n",
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE:  The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "\n",
      "TOKENS:  ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE: ', sentences_nltk[sent_id])\n",
    "print()\n",
    "print('TOKENS: ', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for tokens in tokens_per_sentence:\n",
    "    pos_tags_per_sentence.append(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]\n",
      "\n",
      "Sentence 1: [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence 2: [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n",
      "\n",
      "Sentence 3: [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n",
      "Sentence 4: [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence 5: [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pos_tags in enumerate(pos_tags_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(pos_tags)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_per_sentence = []\n",
    "for tagged_sentence in pos_tags_per_sentence:\n",
    "    ner_tags_per_sentence.append(nltk.chunk.ne_chunk(tagged_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  https/NN\n",
      "  :/:\n",
      "  //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ\n",
      "  Documents/NNS\n",
      "  filed/VBN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  (ORGANIZATION San/NNP Jose/NNP)\n",
      "  federal/JJ\n",
      "  court/NN\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  on/IN\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  list/NN\n",
      "  six/CD\n",
      "  (ORGANIZATION Samsung/NNP)\n",
      "  products/NNS\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (GPE Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  operating/VBG\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (PERSON Apple/NNP)\n",
      "  claims/VBZ\n",
      "  infringe/VB\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  The/DT\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  affected/VBN\n",
      "  are/VBP\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  (PERSON Jelly/NNP Bean/NNP)\n",
      "  system/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  tablet/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (PERSON Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (PERSON Galaxy/NNP S/NNP)\n",
      "  III/NNP\n",
      "  mini/NN\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  (PERSON Apple/NNP)\n",
      "  stated/VBD\n",
      "  it/PRP\n",
      "  had/VBD\n",
      "  “/NNP\n",
      "  acted/VBD\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  in/IN\n",
      "  order/NN\n",
      "  to/TO\n",
      "  ``/``\n",
      "  determine/VB\n",
      "  that/IN\n",
      "  these/DT\n",
      "  newly/RB\n",
      "  released/VBN\n",
      "  products/NNS\n",
      "  do/VBP\n",
      "  infringe/VB\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  asserted/VBN\n",
      "  by/IN\n",
      "  (PERSON Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  In/IN\n",
      "  (GPE August/NNP)\n",
      "  ,/,\n",
      "  (PERSON Samsung/NNP)\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  (GSP US/NNP)\n",
      "  patent/NN\n",
      "  case/NN\n",
      "  to/TO\n",
      "  (GPE Apple/NNP)\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  ordered/VBN\n",
      "  to/TO\n",
      "  pay/VB\n",
      "  its/PRP$\n",
      "  rival/JJ\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  £0.66bn/NN\n",
      "  )/)\n",
      "  in/IN\n",
      "  damages/NNS\n",
      "  for/IN\n",
      "  copying/VBG\n",
      "  features/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION iPad/NN)\n",
      "  and/CC\n",
      "  (ORGANIZATION iPhone/NN)\n",
      "  in/IN\n",
      "  its/PRP$\n",
      "  (GPE Galaxy/NNP)\n",
      "  range/NN\n",
      "  of/IN\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  (GPE Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  world/NN\n",
      "  's/POS\n",
      "  top/JJ\n",
      "  mobile/NN\n",
      "  phone/NN\n",
      "  maker/NN\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  appealing/VBG\n",
      "  the/DT\n",
      "  ruling/NN\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  A/DT\n",
      "  similar/JJ\n",
      "  case/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION UK/NNP)\n",
      "  found/VBD\n",
      "  in/IN\n",
      "  (GPE Samsung/NNP)\n",
      "  's/POS\n",
      "  favour/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (PERSON Apple/NNP)\n",
      "  to/TO\n",
      "  publish/VB\n",
      "  an/DT\n",
      "  apology/NN\n",
      "  making/VBG\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (LOCATION South/JJ Korean/JJ)\n",
      "  firm/NN\n",
      "  had/VBD\n",
      "  not/RB\n",
      "  copied/VBN\n",
      "  its/PRP$\n",
      "  iPad/NN\n",
      "  when/WRB\n",
      "  designing/VBG\n",
      "  its/PRP$\n",
      "  own/JJ\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, ner_tags in enumerate(ner_tags_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(ner_tags)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # Noun Phrase\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_output_per_sentence = [constituent_parser.parse(pos_tags) for pos_tags in pos_tags_per_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  San/NNP\n",
      "  Jose/NNP\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  California/NNP\n",
      "  (P on/IN)\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  Samsung/NNP\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  Bean/NNP\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  Apple/NNP\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  Jelly/NNP\n",
      "  Bean/NNP\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  Galaxy/NNP\n",
      "  Rugby/NNP\n",
      "  Pro/NNP\n",
      "  and/CC\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  Apple/NNP\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  “/NNP\n",
      "  (VP (V acted/VBD))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  Apple/NNP\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  (P In/IN)\n",
      "  August/NNP\n",
      "  ,/,\n",
      "  Samsung/NNP\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  US/NNP\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  Apple/NNP\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP £0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  Galaxy/NNP\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  Samsung/NNP\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  UK/NNP\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  Samsung/NNP\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  Apple/NNP\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, cons_outputs in enumerate(constituency_output_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(cons_outputs)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {<NNP>*}             # ???''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = [constituent_parser_v2.parse(pos_tags) for pos_tags in pos_tags_per_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: (S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  (NEP San/NNP Jose/NNP)\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  (NEP California/NNP)\n",
      "  (P on/IN)\n",
      "  (NEP November/NNP)\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  (NEP Samsung/NNP)\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (NEP Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  (NEP Ice/NNP Cream/NNP Sandwich/NNP)\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 1: (S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  (NEP Jelly/NNP Bean/NNP)\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  8.9/CD\n",
      "  (NEP Wifi/NNP)\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (NEP Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "Sentence 2: (S\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  (NEP “/NNP)\n",
      "  (VP (V acted/VBD))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  (NEP Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "Sentence 3: (S\n",
      "  (P In/IN)\n",
      "  (NEP August/NNP)\n",
      "  ,/,\n",
      "  (NEP Samsung/NNP)\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  (NEP US/NNP)\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  (NEP Apple/NNP)\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP £0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  (NEP Galaxy/NNP)\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "Sentence 4: (S\n",
      "  (NEP Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "Sentence 5: (S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  (NEP UK/NNP)\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  (NEP Samsung/NNP)\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  (NEP Apple/NNP)\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, cons_outputs in enumerate(constituency_v2_output_per_sentence):\n",
    "    print('Sentence '+str(i)+': '+str(cons_outputs)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text) # insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
